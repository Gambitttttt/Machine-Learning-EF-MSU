## Содержание

6) [Градиентный бустинг](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/Градиентный%20бустинг.ipynb)

7) [Нейронные сети](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/NN_intro.ipynb)

| Тема | Материалы | Задания |
| :---: | :---: | :---: |
| Обработка данных в python | <br> [Дьяконов Базовый Python](https://drive.google.com/file/d/1aQ4dwItZNEYSlTwJjYBB3aIBUN4E2IP4/view?usp=sharing) <br> [Дьяконов Pandas](https://drive.google.com/file/d/1XEynEfIvp0R7hlCtZ74Dj8Qxbq4ASkiN/view?usp=sharing) <br> [Дьяконов Numpy](https://drive.google.com/file/d/1Bys5_lLFK_iGcY6VHdNWTTvdORdjYSmm/view?usp=sharing) <br> [Дьяконов sklearn](https://drive.google.com/file/d/1QA_9sYDVK7GiRJw_gm_Yd0Tt-T1HGi8u/view?usp=sharing) | [Курс по базовому питону](https://stepik.org/course/31182/syllabus) <br> <br> [Задачи на pandas](https://github.com/Dyakonov/visualization) <br> <br> [Задачи на numpy и pandas](https://stepik.org/course/3356/syllabus) (Неделя 2 - Векторы, Матрицы) |
| Градиентные методы оптимизации | Основные <br> [Ноутбук](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/Градиентные%20методы%20оптимизации.ipynb) <br>  [Лекция Дьяконова](https://drive.google.com/file/d/1tWfmpLxREVLuN7ZbwdaXA0MPjezNEU9S/view?usp=sharing) <br> [Теория по матричному дифференцированию](https://drive.google.com/file/d/1OocZpnjfYo8elHS3v1P1fHsKXT42jhO-/view?usp=sharing) <br> _________________________________ <br> Дополнительно <br> [Примеры нахождения матричных производных](https://drive.google.com/file/d/1h1n2YXC1QlkGPxJwzddhKbed33MDXMa7/view?usp=sharing) <br> [Интерактивные визуализации методов оптимизации](https://the-learning-machine.com/article/machine-learning/unconstrained-optimization) <br> [Математика в машинном обучении](https://drive.google.com/file/d/1gRVhBINgoFQHWQsUTXfZoi0BOcLDU0Th/view?usp=sharing) (225 страница, Continuous optimization)| [Семинарские задачи](https://www.overleaf.com/read/vgfsbdmssjsd) <br> <br> [Практическая](https://www.overleaf.com/read/tvmjbwbrrmyr) |
| Метрические методы | Основные <br> [Соколов KNN](https://drive.google.com/file/d/1WXuTsdGTdjNl5aZPD111klB7HiUjrbzI/view?usp=sharing) <br> [Дьяконов Метрические методы](https://drive.google.com/file/d/1An7wO3EFufOnsRur_rquShTp85OZCU3o/view?usp=sharing) <br> [Дьяконов Валидация моделей](https://drive.google.com/file/d/1lOunHT6sOKPAmOoWHiWukK1rNzNAEOiT/view?usp=sharing) <br> [Соколов KNN (с картинками)](https://drive.google.com/file/d/1AegrIBZyc0w7piKlb1fRDdlWxUEb17u_/view?usp=sharing) <br> [Соколов Обучение метрик](https://drive.google.com/file/d/1XNxnxyo_0mahN_PFglduqgTEI61aOgaV/view?usp=sharing) <br> [Соколов Приближённые методы поиска ближайших соседей](https://drive.google.com/file/d/1UrIwpIRfkfnK5GLEicFFHz8HIpHMRrsz/view?usp=sharing)  <br> _________________________________ <br> Дополнительно <br> [Ноутбук](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/Лекция_Метрические%20методы%20классификации%20и%20регрессии.ipynb) <br> | [Семинарские задачи](https://www.overleaf.com/read/nwpbtbfwczpn)  |
| Логические методы | Основные <br>  [Соколов Решающие деревья](https://drive.google.com/file/d/1l-aU5hwYwoKkJ8J9bWSDslTr0rondXOB/view?usp=sharing) <br> [Дьяконов Решающие деревья](https://drive.google.com/file/d/1eyNlV-YHIauBbogcbl4aNU5_McdAROgn/view?usp=sharing) <br> _________________________________ <br> Дополнительно <br> [Соколов деревья с картинками](https://drive.google.com/file/d/1H0PaZlZbRf6Xzgi0qM4yyHi-v0aNfkux/view?usp=sharing) <br> [Соколов Пример построения дерева](https://drive.google.com/file/d/1blrmIgJQr5KzD-7ZOwqmt59F_qp_-juM/view?usp=sharing) <br> [Uplift моделирование с помощью деревьев](https://habr.com/ru/company/ru_mts/blog/485976/) | [Семинарские задачи](https://www.overleaf.com/read/gytnbjdzgfwr) |
| Метрики качества | Основные <br> [Соколов Метрики качества бинарной классификации](https://drive.google.com/file/d/1-oH5QhlRydpjhEW8nXH7XBJYewdKoF23/view?usp=sharing) <br> [Дьяконов Метрики качества](https://drive.google.com/file/d/1DmVmgWQtqjrqmBwJj9b-gcmjdIXcYlp4/view?usp=sharing) <br> [Соколов Метрики качества многоклассовой классификации](https://drive.google.com/file/d/1rgHnWLhr6Yn2AkVvOL5jRDq6pqc8snHP/view?usp=sharing) <br> [Соколов ROC-AUC](https://drive.google.com/file/d/1aSkFzpJM-fHNh72CKErGB9gpxONg2z-W/view?usp=sharing) <br> _________________________________ <br> Дополнительно <br> [Дьяконов ROC-AUC](https://dyakonov.org/2017/07/28/auc-roc-площадь-под-кривой-ошибок/) <br> [Дьяконов Кривые в ML](https://dyakonov.org/2019/08/29/кривые-в-машинном-обучении/) | [Семинарские задачи](https://www.overleaf.com/read/dftcbbbympfx) |
| Линейные методы | Основные <br> [Соколов Обучение линейных классификаторов в общем виде](https://drive.google.com/file/d/1woYoeB3Hs4hpCR4xUzRG-9UMSXsuEDnp/view?usp=sharing) <br> [Соколов SVM и Logreg](https://drive.google.com/file/d/1gm-mHah8g3SxqAzV9-M3SRFhUQgETXax/view?usp=sharing) <br> [Дьяконов Линейные методы](https://drive.google.com/file/d/1IaDedfHY65n7UVUw9wI_-67BsQ14Nic_/view?usp=sharing) <br> [Теория SVM](https://drive.google.com/file/d/1gRVhBINgoFQHWQsUTXfZoi0BOcLDU0Th/view?usp=sharing) (370 страница, Classification with Support Vector Machines)  <br> __________________________________ <br> Дополнительно <br> [Ноутбук логрег](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Seminars/Демонстрация%20логистической%20регрессии.ipynb) <br> [Ноутбук по условной оптимизации и SVM](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/Условная%20оптимизация%20и%20SVM.ipynb) <br> [Соколов logreg с картинками](https://drive.google.com/file/d/165Imi2mxAzbFJwORFxxvcuExoB3j6VqX/view?usp=sharing) <br> [Соколов SVM с картинками](https://drive.google.com/file/d/1kBce7P73lg1DaXiVLZxLWP2rP0CFomti/view?usp=sharing)  <br> __________________________________ <br> Ликбез по условной оптимизации <br> [Условная оптимизация](https://drive.google.com/file/d/1ntD2mlob1jWemiIftkN1vSWvL_Vctrau/view?usp=sharing) <br> [Теория ККТ с примерами](https://drive.google.com/file/d/1M546yxrsD5oQT5Ek91auzGbLBCKeDPeA/view?usp=sharing) <br> [Теория двойственности](https://drive.google.com/file/d/1h106yD-wfxlfUAq7I6MyGaOKAT0pIqdB/view?usp=sharing) <br> [Заметки о решении задач условной оптимизации](https://drive.google.com/file/d/1KdtRpe1WJtJVGX6RLLWGYxbdRSbTaKR5/view?usp=sharing) | [Семинарские задачи](https://www.overleaf.com/read/fvbgqvgbhnxt) |
| Ядровые методы | Основные <br> [Соколов. Ядра 1](https://drive.google.com/file/d/1jVRsFJ_2J9Z-CSP8OS0A2zRuC_EnL-vZ/view?usp=sharing) <br> [Соколов. Ядра 2](https://drive.google.com/file/d/1LKJQinTgSUkNJKhm8Am_1YDZX4QTKBw_/view?usp=sharing) <br> [Соколов. Ядра 3](https://drive.google.com/file/d/1ywlp7dC-NA0K0bdC3dJCncHIcfuOyF3x/view?usp=sharing) <br> [Соколов. Ядра 4](https://drive.google.com/file/d/1mowSUd-iuNXjB5IANYMQz6ZEY6Bsm_na/view?usp=sharing) <br> [Математика в машинном обучении](https://drive.google.com/file/d/1gRVhBINgoFQHWQsUTXfZoi0BOcLDU0Th/view?usp=sharing) (388 страница, Kernels)| [Семинарские задачи](https://www.overleaf.com/read/swrcyzvbbcjy) | 
| Обучение без учителя | Embeddings <br> [Снижение размерности и кластеризация](https://nbviewer.jupyter.org/github/andreitsev/Machine-Learning-EF-MSU/blob/master/Lectures/Снижение%20размерности%20и%20Кластеризация.ipynb) (ноутбук) <br> [Соколов PCA](https://drive.google.com/file/d/1lkfVAdmLKDpWgNf4SetqOjZru-j2Yb6L/view?usp=sharing) <br> [Word2Vec](https://lena-voita.github.io/nlp_course/word_embeddings.html) <br> [Соколов t-SNE](https://drive.google.com/file/d/1HuB09_vrGUe9G8E_Jcw61okrGSkwUlts/view?usp=sharing) <br> [Математика в машинном обучении](https://drive.google.com/file/d/1gRVhBINgoFQHWQsUTXfZoi0BOcLDU0Th/view?usp=sharing) (стр. 317, Dimensionality Reduction with Principal Component Analysis) <br> __________________________________ <br> Кластеризация <br> [Соколов Кластеризация](https://drive.google.com/file/d/1HuB09_vrGUe9G8E_Jcw61okrGSkwUlts/view?usp=sharing) <br> [DBSCAN](https://habr.com/ru/post/322034/) <br> __________________________________ <br> Дополнительно <br> [clustering+tsne](https://colab.research.google.com/drive/16OkfhtpvioTKh1PfYT_EL80fFdnBVtb1?authuser=4) (ноутбук) <br> [Байесовский вариант PCA](https://drive.google.com/file/d/1Nq0mkvh-m7z0ggDFBrRv9XiD1nEVBEGe/view?usp=sharing) <br> [Embeddings в рекомендательных системах](https://drive.google.com/file/d/1dxbdmKlC5ilwanaXj0BoCqKC8esz1bjF/view?usp=sharing) (2.1.2 Модели со скрытыми переменными) <br> [t-SNE paper](https://drive.google.com/file/d/1kiUYHee5FJWz74mtELfs-sHm_f8StAdL/view?usp=sharing) <br> [Соколов про t-SNE](https://drive.google.com/file/d/10QOcmthhxBJs4Wf2F26-fECwLMuyxCCd/view?usp=sharingГиперссылка) (Обратите внимание, что там потерян минус в определении условных вероятностей p и q)| [Семинарские задачи](https://www.overleaf.com/read/xpvbtnsybxzd) |


#### Полезные ссылки:

[Гитхаб Дьяконова](https://github.com/Dyakonov?tab=repositories):

- [IML](https://github.com/Dyakonov/IML) - курс по машинному обучению для 1-2 курсов.
- [MLDM](https://github.com/Dyakonov/MLDM/tree/master/2019) - потоковый курс по ML для 3их курсов
- [DL](https://github.com/Dyakonov/DL) - курс по глубокому обучению

[Курсы ФКН](http://wiki.cs.hse.ru/Заглавная_страница):

- [Соколов. ML1](http://wiki.cs.hse.ru/Машинное_обучение_1/2020_2021)
- [Соколов. ML2](http://wiki.cs.hse.ru/Машинное_обучение_2)